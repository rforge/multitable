\documentclass{article}
\usepackage{graphicx}
\usepackage{url}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{hyperref}
\usepackage{verbatim}


%\VignetteIndexEntry{Reading multiple tables of data}
%\VignettePackage{multitable}
%\VignetteDepends{multitable}
%\VignetteKeywords{data manipulation, ecology, multivariate, R}


%%%%R commands for running Sweave%%%%%%%
%%%%setwd("/users/stevenwalker/documents/multitable/multitable/vignettes/readingmultipletables/")
%%%%Sweave("/users/stevenwalker/documents/multitable/multitable/vignettes/readingmultipletables/readingmultipletables.Rnw")

\newcommand{\R}{{\sf R}}
\newcommand{\code}[1]{\texttt{#1}}
\title{Reading multiple tables of data into \R}
\author{SC Walker}

\newcounter{exercise}
\numberwithin{exercise}{section}
\newcommand{\exnumber}{\addtocounter{exercise}{1} \theexercise \thinspace}

\begin{document}
\maketitle

The \code{multitable} package works by organizing multiple-table data into special \R\ objects called \code{data.list}s.  If you do not have the \code{multitable} package, you can get it \href{https://r-forge.r-project.org/R/?group_id=1171}{here}.  Everything in this vignette assumes that this package is installed and loaded, for example with the \code{library} function,
<<eval=TRUE>>=
library(multitable)
@

There are many methods for converting multiple-table data into a \code{data.list}.  The methods largely differ based on the format of the data to be converted.  Table \ref{tab:functions} gives a list of functions that can be used to create \code{data.list} objects, and the \R\ objects that they take as input.  This vignette illustrates the use of several of these functions.

\begin{table}[h]
\caption{Functions that generate \code{data.list} objects as output}
\begin{center}
\begin{tabular}{p{3cm}p{8cm}}
\hline
Function & Input objects \\
\hline
\code{as.data.list} & either a \code{vector}; \code{matrix}; \code{array}; \code{data.frame}; \code{list}; or a \code{list} of such objects \\
\code{data.list} & a number of \code{vector}s; \code{matrix}es; \code{array}s; \code{data.frame}s; and \code{list}s \\
\code{dlcast} & a \code{list} of long-format \code{data.frame}s \\
\code{read.multitable} & \code{vector} of character strings giving filenames of long-format text files \\
\code{read.multicsv} & \code{vector} of character strings giving filenames of long-format comma-separated text files \\
\code{read.multidelim} & \code{vector} of character strings giving filenames of long-format tab-delimited text files \\
\code{read.fourthcorner} & three character strings giving filenames of the data tables that define a fourth-corner problem \\
\hline
\end{tabular}
\end{center}
\label{tab:functions}
\end{table}

%Here we organize this vignette by considering ?? approaches for doing so.  If your data are in standard `fourth-corner' format and would like to get going as quickly as possible, see Section ??.  If you would like a good general-purpose step-by-step method that follows many of the `best-practices' often recommended in data management, then I recommend Section ??.  This section covers recommendations on how to format your data in Excel / text files, right up to the commands required to read these files into \R.  If you would like to understand some of the details behind these `best-practices' see Section ??.  And if you do not appreciate being told how to get your data into standard \R\ objects (e.g. \code{data.frame}s; \code{matrix}es), and would like to simply combine such objects into a \code{data.list} then see Section ??.

\newpage

\section{Reading fourth corner data}

Figure \ref{fig:spreadsheetfc} \begin{figure}
\label{fig:spreadsheetfc}
\includegraphics{./readingmultipletables/community.pdf}
\includegraphics{./readingmultipletables/environment.pdf}
\includegraphics{./readingmultipletables/traits.pdf}
\caption{Fictitious fourth-corner data set.}
\end{figure}shows three spreadsheets containing the data for a simple fourth-corner problem.  The first sheet gives species abundance data for three species (capybara; moss; vampire) at six sites (arctic; subarctic; midlatitude; subtropical; tropical; equatorial).  The second and third sheets give two environmental variables (temperature; precipitation) at each site and two traits (body size; metabolic rate) for each species.  We are going to convert these spreadsheets into an \R\ object that contains all of these variables, relating them along their shared dimensions.

Although it is possible to load spreadsheets directly into \R, it is usually better to first convert them into text files---I follow this \href{http://cran.r-project.org/doc/manuals/R-data.html#Reading-Excel-spreadsheets}{standard advice}.  To convert to a text file, open a spreadsheet, select \code{save as} from a menu, and choose a text file format (e.g. comma separated .csv file).

Once each of these three data tables is stored as a text file, then one line of \R\ code will read them all into a \code{data.list} object using the \code{read.fourthcorner} function in the \code{multitable} package,
<<eval=TRUE>>=
setwd("./readingmultipletables/")
fc <- read.fourthcorner("community.csv","environment.csv","traits.csv",sep=",",header=TRUE,row.names=1)
@
Note that this line assumes that the files are in the working directory.  If this is not true, then include the path in the string just as you would do with \code{read.table} or \code{read.csv}.  Alternatively, the \code{file.choose} function could be used as follows,
<<eval=FALSE, echo=TRUE>>=
fc <- read.fourthcorner(file.choose(),file.choose(),file.choose(),sep=",",header=TRUE,row.names=1)
@
to invoke an interactive menu for selecting the appropriate files.  The \code{header=TRUE} argument indicates that the first line in each file gives the names of the columns and \code{row.names=1} indicates that the first column in each file gives the names of the rows.  The \code{fc} object looks like this,
<<eval=TRUE>>=
fc
@
and can be passed to various \R\ functions such as,
<<eval=TRUE>>=
glm(abundance~(temperature+precipitation)*(body.size+metabolic.rate),family=poisson,data=fc)
@

\section{Fourth corner data in long format}

Looking at these community data, we see that some species were not present at many sites (e.g. the rare and metabolically inert vampire species).  Such sparsity is a common feature of community data, because most species are absent or rare at most places (refs?).  Because sparsity is common, we can save space by storing these data in `long' format (Fig. \ref{fig:longspreadsheetfc}). \begin{figure}
\label{fig:longspreadsheetfc}
\includegraphics{./readingmultipletables/community_long.pdf}
\includegraphics{./readingmultipletables/environment_long.pdf}
\includegraphics{./readingmultipletables/traits_long.pdf}
\caption{Fictitious fourth-corner data set in `long' format.}
\end{figure}In this format, the community data becomes a single column (i.e. abundance).  The site and species that correspond to each abundance is identified by two additional columns (i.e. sites; species).  Notice that none of the zeros are stored, because it is implied that a species was not detected at a site if that site-species combination is not present in the long-format data.

The benefits of the long format are not just to save memory, which currently may seem quite unimportant given the size of contemporary storage devices.  However, there are other more important benefits.  Notice that in long format (Fig. \ref{fig:longspreadsheetfc}), the environment and traits matrix are almost identical as before (Fig. \ref{fig:spreadsheetfc}), except that the sites and species columns now have headings.  These headings specify how the tables are related.  Specifically, the abundance variable is replicated along both sites and species, temperature and precipitation are replicated along sites only, whereas body size and metabolic rate are replicated along species only.  Hence, the long format enjoys a certain conceptual simplicity:  each column denotes either a variable or a dimension of replication.  Such a format has the desirable property that additional sampling will add more rows, but never any columns.  Database management is much easier for such formats (refs?).  In contrast, the standard fourth-corner format (Fig. \ref{fig:spreadsheetfc}) will often require more columns as new sites are sampled, as a result of the species discovery process.  Furthermore, the long-format easily handles three- (or higher-) dimensional data cubes (or hyper-cubes), by simply adding additional columns for each dimension (see example ?? below); this is not possible in fourth-corner format.

To read data in long format into a \code{data.list}, we can use one of the functions from the \code{read.multitable} family of functions.  These functions are simply wrappers for the standard \code{read.table} functions in the \R\ \code{utils} package, so that these utilities can be used with multiple-table data.  Here we use \code{read.multicsv} to read in \code{.csv} versions of the data in Figure \ref{fig:longspreadsheetfc},
<<eval=TRUE>>=
files <- c("community_long.csv","environment_long.csv","traits_long.csv")
dnames <- c("sites","species")
fc <- read.multicsv(files,dnames,fill=c(0,NA,NA))
@
or with interactive menus,
<<eval=FALSE,echo=TRUE>>=
fc <- read.multicsv(multifile.choose(3),dnames,fill=c(0,NA,NA))
@
These commands store exactly the same \code{fc} object that we obtained before.  Note the \code{fill=c(0,NA,NA)} argument, which causes any missing site-species combinations to be filled with zeros and to fill missing environmental variables or traits with \code{NA}.

\section{More complex multiple-table data}

Notwithstanding its small size, the above example is extremely simple; it contains only numeric data, has no missing values, and has only two dimensions of replication.  Here I provide an example (Fig. \ref{fig:complexspreadsheet}) \begin{figure}
\label{fig:complexspreadsheet}
\includegraphics{./readingmultipletables/community_complex.pdf}
\includegraphics{./readingmultipletables/environment_complex.pdf}
\includegraphics{./readingmultipletables/traits_complex.pdf}
\caption{Complex fictitious data set in `long' format.}
\end{figure}that relaxes those simplifications.  For the sake of space I resisted the temptation to add another file, although such an addition would pose no further difficulties.

This data set is quite a bit more complex, yet it can be read in a very similar manner to the previous data set.  The only difference is that a \code{"years"} dimension of replication must be specified.

<<eval=TRUE>>=
files <- c("community_complex.csv","environment_complex.csv","traits_complex.csv")
dnames <- c("sites","years","species")
fc <- read.multicsv(files,dnames,fill=c(0,NA,NA))
fc
@

\section{Creating data lists from existing \R\ objects}

So far we have covered the use of convenience functions (e.g. \code{read.multicsv}; \code{read.fourthcorner}) for directly converting multiple-table data into a \code{data.list} object.  However, experienced \R\ users will already be good at getting their data into \R\ and many such users may not wish to use our new functions, as how best to read data into \R\ is arguably a subjective matter.  Here we describe how to create \code{data.list}s from several objects (e.g. vectors; matrices; arrays; data frames; lists) that are already in \R, highlighting cases that could cause difficulties.

\subsection{Standard fourth-corner data}

<<eval=TRUE, echo=FALSE>>=
l <- lapply(c("community.csv","environment.csv","traits.csv"),read.csv,header=TRUE,row.names=1)
community <- l[[1]]
environment <- l[[2]]
traits <- l[[3]]
@

Consider the following three data frames each containing part of our first data set,

<<eval=TRUE>>=
community
environment
traits
@

We begin with a potentially frustrating issue that could arise, and then describe its solution.  The \code{multitable} package contains a \code{data.list} function for combining multiple \R\ objects into a data list.  This function is analogous to the \code{data.frame} in the \R\ \code{base} package.  However, if we try to pass these three objects to \code{data.list}, we will get an error,
<<echo=TRUE, eval=FALSE>>=
data.list(community,environment,traits,dnames=c("sites","species"))
@
<<echo=FALSE, eval=TRUE,results=verbatim>>=
try.out <- try(data.list(community,environment,traits,dnames=c("sites","species")))
cat(try.out)
@

Why didn't this work?  Well, the quick answer is that data lists must contain at least one variable that is replicated along all the dimensions of replication used by all other variables (see vignette on ????).  But why did our code result in a data list without a variable that is replicated along all dimensions (i.e. along both sites and species)?  The answer is important for understanding multiple-table data in \R, and has to do with the differences between data frames and matrices.  In standard \R\ workflows we usually don't need to worry about these differences, because many functions have the ability to work equally well with either a matrix or a data frame.  But this approach will not work with multiple-table data, because \code{data.list} will treat matrices and data frames very differently even though they look very similar.

So what's the difference between matrices and data frames?  In technical terms, a matrix is an atomic vector with a dimension attribute whereas a data frame is a list of atomic vectors without a dimension attribute.  In less technical terms, a matrix is one single variable that has been replicated along two dimensions (represented by the rows and the columns); on the other hand, a data frame is a group of several variables (represented by the columns) that has been replicated along a single dimension (represented by the rows).  The reason why this technicality is important in practice is that the structure provided by data lists is based on a distinction between dimensions of replication and groups of variables.  When a matrix is passed to \code{data.list} it `thinks' its getting one single variable that has been replicated along two dimensions, but when it gets a data frame it `thinks' its getting several variables that have only been replicated along a single dimension.

So which of our three tables should be matrices and which should be data frames?  The \code{environment} and \code{traits} tables should remain as data frames because temperature, precipitation, body size, and metabolic rate are each different variables replicated along either sites or species.  The \code{community} table should be a matrix because it is a single variable (i.e. abundance), which is replicated along both sites and species.  The error message of the previous code now makes sense.  Because we entered each of our tables as data frames, we implied that all variables were only replicated along a single dimension:  species abundances and environmental variables were replicated along sites whereas traits were replicated along species.  Therefore, none of our variables were replicated along both dimensions (i.e. sites and species), making it impossible to relate the tables.

By coercing the community data to a matrix, we can create exactly the same data list object that we obtained above for these data.
<<eval=TRUE>>=
abundance <- as.matrix(community)
dl <- data.list(abundance,environment,traits,dnames=c("sites","species"))
@

\subsection{Fourth-corner data in long format data frames}

Now suppose that the data objects are in `long' format,

<<eval=TRUE, echo=FALSE>>=
l <- lapply(c("community_long.csv","environment_long.csv","traits_long.csv"),read.csv,header=TRUE)
community <- l[[1]]
environment <- l[[2]]
traits <- l[[3]]
@

<<eval=TRUE>>=
community
environment
traits
@

We can use the \code{dlcast} function to combine these tables into a data list.  The following code will again produce an identical data list,
<<eval=TRUE>>=
dl <- dlcast(list(community,environment,traits),dnames=c("sites","species"),fill=c(0,NA,NA))
@
The \code{dlcast} function is inspired by the \code{acast} function from the \code{reshape2} package.  The \code{acast} function converts a long-format data frame into an array depending on which variables are identified as defining the dimensions of the resulting array and which variable is used to fill it.  

\begin{comment}

\section{General principles for smooth data list creation}

\subsection{How data list creation works}

One way to create data lists hassle-free is to understand a little bit about how the creation functions work.  The real workhorse function for data list creation is \code{as.data.list}; a call to any function in Table \ref{tab:functions} will automatically result in a call to this function, which converts a single \R\ object into a data list.  For example, we could convert a single vector into a fairly useless data list,
<<eval=TRUE>>=
as.data.list(c(4,2,7,4))
@
\noindent Here are some other examples.
<<eval=TRUE>>=
X <- data.frame(A=rbinom(5,1,0.5),B=rbinom(5,1,0.5))
as.data.list(X)

X <- array(letters[1:24],dim=c(4,3,2))
as.data.list(X)

X <- list(matrix(rbinom(15,1,0.5),5,3),matrix(rbinom(15,1,0.5),5,3))
as.data.list(X)

Y <- matrix(runif(15),5,3)
X <- data.frame(runif(5))
Z <- data.frame(runif(3))
as.data.list(list(Y,X,Z))
@

\noindent Here I briefly describe the algorithm used by \code{as.data.list}.



\subsection{Make sure all of the dimensions of your input objects are consistently named}



\subsection{Manual dimension matching with \code{match.dnames}} 



\subsection{Sometimes \code{data.list} requires more structure}

<<eval=TRUE, echo=FALSE>>=
l <- lapply(c("community_smalllong.csv","environment_smalllong.csv","traits_smalllong.csv"),read.csv,header=TRUE)
community <- l[[1]]
environment <- l[[2]]
traits <- l[[3]]
@

<<eval=TRUE>>=
community
environment
traits
@

<<eval=TRUE>>=
dl <- dlcast(list(community,environment,traits),dnames=c("sites","species"),fill=c(0,NA,NA))
dl
@

\end{comment}

\end{document}
